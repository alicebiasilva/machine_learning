{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnicas de otimização e ajuste fino"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No aprendizado de máquina supervisionado, a otimização e o ajuste fino são etapas cruciais para alcançar o melhor desempenho possível de um modelo. O objetivo é ajustar de forma precisa os hiperparâmetros para melhorar a capacidade de generalização e robustez do modelo, evitando problemas como overfitting ou underfitting.\n",
    "\n",
    "Uma técnica importante para otimização é o Grid Search, que consiste em testar diferentes combinações de hiperparâmetros e comparar o desempenho do modelo com base em uma métrica escolhida. Embora seja eficaz, pode ser computacionalmente caro, principalmente quando há muitos parâmetros ou valores possíveis para testar.\n",
    "\n",
    "Outro conceito fundamental é a validação cruzada, que é usada para avaliar a capacidade de generalização do modelo. Ao invés de dividir os dados apenas uma vez entre treino e teste, a validação cruzada divide os dados em várias partes (folds), e o modelo é treinado e validado em diferentes subconjuntos. A técnica mais comum é o K-Fold Cross-Validation, onde os dados são divididos em k partes, e o modelo é treinado e avaliado k vezes, com cada parte servindo como conjunto de validação uma vez. Isso ajuda a reduzir a variabilidade nos resultados, fornecendo uma estimativa mais robusta de como o modelo vai se comportar em dados não vistos. Quando há desequilíbrio nas classes do conjunto de dados, utiliza-se o Stratified K-Fold, que mantém a proporção de classes em cada fold. Já o Leave-One-Out Cross-Validation utiliza uma amostra por vez para validação, oferecendo uma avaliação muito detalhada, mas com um custo computacional elevado.\n",
    "\n",
    "Os conceitos de overfitting e underfitting são centrais nesse contexto. O overfitting ocorre quando o modelo se adapta demais aos dados de treinamento, aprendendo padrões específicos que não se generalizam bem para dados novos. Isso pode acontecer quando o modelo é excessivamente complexo, quando há muito pouco dado de treinamento ou quando o treinamento é realizado por tempo demais. Já o underfitting acontece quando o modelo não aprende o suficiente com os dados, seja por ser muito simples, por não ter dados suficientes ou por não ser treinado adequadamente, resultando em um desempenho ruim.\n",
    "\n",
    "Para evitar o overfitting e o underfitting, algumas estratégias são adotadas. O aumento do conjunto de dados pode ajudar a melhorar a generalização, fornecendo mais exemplos para o modelo aprender. Além disso, a limpeza de dados, removendo ruídos e outliers, pode melhorar a qualidade do treinamento. A validação cruzada é essencial para garantir que o modelo não está apenas decorando os dados de treino, mas sim aprendendo padrões que se aplicam a dados novos. A seleção de modelos também é crucial, pois escolher o modelo com a complexidade correta pode ajudar a evitar o overfitting (com modelos muito complexos) e o underfitting (com modelos muito simples).\n",
    "\n",
    "Técnicas como dropout, usadas em redes neurais, ajudam a evitar que o modelo se dependa demais de neurônios específicos durante o treinamento, tornando-o mais robusto. O early stopping é outra técnica que interrompe o treinamento do modelo assim que o desempenho no conjunto de validação começa a piorar, evitando que o modelo aprenda padrões específicos demais do conjunto de treinamento.\n",
    "\n",
    "No final, o objetivo é encontrar o equilíbrio entre overfitting e underfitting. Isso pode ser feito usando técnicas como validação cruzada e ajustando os hiperparâmetros do modelo. A chave é treinar o modelo de forma adequada, garantindo que ele aprenda os padrões corretos dos dados, sem memorizar excessivamente os detalhes, e seja capaz de generalizar bem para novos exemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np  \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import mean_absolute_percentage_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\".\\datasets\\kc_house_data.csv\", encoding = 'utf-8', sep= ';')\n",
    "df = df[['price', 'bedrooms', 'bathrooms', 'sqft_living', \n",
    "'sqft_lot', 'floors', 'waterfront']] \n",
    " \n",
    "x = df.drop('price', axis=1) \n",
    "y = df['price'] \n",
    " \n",
    "# normalização dos dados \n",
    "min_max_scaler = StandardScaler() \n",
    "x = min_max_scaler.fit_transform(x) \n",
    "\n",
    "# Criando o modelo de regressão linear \n",
    "linear_regressor = LinearRegression() \n",
    " \n",
    "# Definindo o número de folds \n",
    "k = 5 \n",
    " \n",
    "# Criando o objeto KFold \n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42) \n",
    " \n",
    "# Armazenará os scores de cada fold \n",
    "mape_scores = [] \n",
    " \n",
    "# Realizando o K-Fold Cross-Validation \n",
    "for train_index, val_index in kf.split(x): \n",
    "    x_train, x_val = x[train_index], x[val_index] \n",
    "    y_train, y_val = y[train_index], y[val_index] \n",
    " \n",
    "    # Treinando o modelo no conjunto de treino \n",
    "    linear_regressor.fit(x_train, y_train) \n",
    " \n",
    "    # Fazendo previsões no conjunto de validação \n",
    "    y_pred = linear_regressor.predict(x_val) \n",
    " \n",
    "    # Calculando o erro percentual absoluto médio (MAPE) \n",
    "    mape = mean_absolute_percentage_error(y_val, y_pred) \n",
    " \n",
    "    # Armazenando o MAPE para cada fold \n",
    "    mape_scores.append(mape)\n",
    "\n",
    "# Calculando o MAPE médio \n",
    "mape_mean = np.mean(mape_scores) \n",
    "print(f\"MAPE médio: {mape_mean}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dados de treino (para a validação cruzada) e de teste \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "test_size=0.1, random_state=0) \n",
    "\n",
    "# Criando o modelo de regressão linear \n",
    "linear_regressor = LinearRegression() \n",
    "\n",
    "# Definindo o número de folds \n",
    "k = 5 \n",
    "\n",
    "# Criando o objeto KFold \n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42) \n",
    "\n",
    "# Armazenará os scores de cada fold \n",
    "mape_scores = [] \n",
    "\n",
    "# Realizando o K-Fold Cross-Validation \n",
    "for train_index, val_index in kf.split(x_train, y_train): \n",
    "    x_train_cv, x_val = x[train_index], x[val_index] \n",
    "    y_train_cv, y_val = y[train_index], y[val_index] \n",
    "\n",
    "    # Treinando o modelo no conjunto de treino \n",
    "    linear_regressor.fit(x_train_cv, y_train_cv) \n",
    "\n",
    "    # Fazendo previsões no conjunto de validação \n",
    "    y_pred = linear_regressor.predict(x_val) \n",
    " \n",
    "    # Calculando o erro percentual absoluto médio (MAPE) \n",
    "    mape = mean_absolute_percentage_error(y_val, y_pred) \n",
    " \n",
    "    # Armazenando o MAPE para cada fold \n",
    "    mape_scores.append(mape) \n",
    " \n",
    "# Calculando o MAPE médio \n",
    "mape_mean = np.mean(mape_scores) \n",
    " \n",
    "print(f\"MAPE médio: {mape_mean}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vendo a performance agora do modelo para o conjunto de teste \n",
    " \n",
    "# Fazendo previsões no conjunto de teste \n",
    "y_pred_2 = linear_regressor.predict(x_test) \n",
    " \n",
    "# Calculando o erro percentual absoluto médio (MAPE) \n",
    "mape_test = mean_absolute_percentage_error(y_test, y_pred_2) \n",
    " \n",
    "print(f\"MAPE: {mape_test}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import SVR \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "test_size=0.1, random_state=0) \n",
    " \n",
    "# Definindo os parâmetros a serem ajustados \n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]} \n",
    " \n",
    "# Criando o modelo \n",
    "svr = SVR() \n",
    " \n",
    "# Ajuste fino \n",
    "clf = GridSearchCV(svr, parameters) \n",
    " \n",
    "# Treinando o modelo com otimização \n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.cv_results_['params']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(clf.cv_results_) \n",
    "df_results.query(\"rank_test_score == 1\")['params'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "test_size=0.1, random_state=0) \n",
    "# Definindo os parâmetros a serem ajustados \n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]} \n",
    "# Criando o modelo \n",
    "svr = SVR() \n",
    "# Ajuste fino com validação cruzada \n",
    "clf = GridSearchCV(svr, parameters, cv=10) \n",
    "# Treinando o modelo com otimização \n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_params_) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88c6fc5200eda66d23d3a5ff1580f04e7d912c56a501f74c19d53579eeb803ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
