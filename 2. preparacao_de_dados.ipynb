{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepara√ß√£o de dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No contexto de machine learning, o pr√©-processamento de dados √© uma etapa fundamental que antecede a constru√ß√£o e o treinamento de modelos. Raramente os dados brutos coletados de fontes reais est√£o prontos para uso imediato: eles costumam conter valores ausentes, ru√≠dos, inconsist√™ncias, escalas distintas e formatos inadequados para os algoritmos de aprendizado.\n",
    "\n",
    "O objetivo do pr√©-processamento √© transformar esses dados brutos em um conjunto mais limpo, consistente e informativo, capaz de representar adequadamente o problema a ser resolvido. Entre as principais tarefas dessa etapa est√£o a limpeza dos dados, o tratamento de valores faltantes, a normaliza√ß√£o ou padroniza√ß√£o de atributos, a codifica√ß√£o de vari√°veis categ√≥ricas e a sele√ß√£o ou extra√ß√£o de caracter√≠sticas relevantes.\n",
    "\n",
    "Alguns exemplos de t√©cnicas de pr√©-processamento amplamente utilizadas incluem:\n",
    "\n",
    "- Tratamento de valores ausentes, como remo√ß√£o de registros incompletos ou imputa√ß√£o usando m√©dia, mediana, moda ou modelos preditivos.\n",
    "- Normaliza√ß√£o e padroniza√ß√£o, por meio de t√©cnicas como Min-Max Scaling e Standardization (z-score), que ajustam as escalas das vari√°veis num√©ricas.\n",
    "- Codifica√ß√£o de vari√°veis categ√≥ricas, utilizando m√©todos como One-Hot Encoding ou Label Encoding.\n",
    "- Detec√ß√£o e tratamento de outliers, com t√©cnicas estat√≠sticas (como IQR e desvio padr√£o) ou m√©todos baseados em modelos.\n",
    "- Sele√ß√£o de atributos, empregando filtros estat√≠sticos, wrapper methods ou t√©cnicas embutidas (embedded methods), a fim de reduzir dimensionalidade e ru√≠do.\n",
    "- Extra√ß√£o de caracter√≠sticas, como Principal Component Analysis (PCA), que transforma os dados em um novo espa√ßo de menor dimens√£o.\n",
    "\n",
    "Um bom pr√©-processamento impacta diretamente o desempenho dos modelos de machine learning, pois algoritmos aprendem padr√µes com base na qualidade das informa√ß√µes fornecidas. Dados mal preparados podem levar a modelos imprecisos, enviesados ou inst√°veis, enquanto um pr√©-processamento adequado contribui para maior efici√™ncia, melhor generaliza√ß√£o e resultados mais confi√°veis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import normalize, StandardScaler, OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Cria√ß√£o de um df de exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome</th>\n",
       "      <th>simbolo</th>\n",
       "      <th>idade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peter</td>\n",
       "      <td>aranha</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bruce</td>\n",
       "      <td>,morcego</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T'Challa</td>\n",
       "      <td>pantera</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nome   simbolo idade\n",
       "0     Peter    aranha    22\n",
       "1     Bruce  ,morcego   NaT\n",
       "2  T'Challa   pantera    25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"nome\": ['Peter', 'Bruce', \"T'Challa\"],\n",
    "                    \"simbolo\": ['aranha', ',morcego', 'pantera'],\n",
    "                    \"idade\": [22, pd.NaT, 25]                    \n",
    "                    })\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Valores ausentes\n",
    "\n",
    "Op√ß√µes para tratar:\n",
    "* remo√ß√£o: eliminar linhas ou colunas com valores ausentes, caso a quantidade seja significativa\n",
    "* imputa√ß√£o: preencher os valores ausentes com valores estimados, como m√©dia, mediana ou valores previstos por um modelo auxiliar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Remo√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome</th>\n",
       "      <th>simbolo</th>\n",
       "      <th>idade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peter</td>\n",
       "      <td>aranha</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T'Challa</td>\n",
       "      <td>pantera</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nome  simbolo idade\n",
       "0     Peter   aranha    22\n",
       "2  T'Challa  pantera    25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna() #n√£o altera o df, s√≥ visualiza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True) #altera o df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Imputa√ß√£o "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3., nan],\n",
       "       [ 4., nan,  6.,  7.],\n",
       "       [ 8.,  2.,  5.,  7.],\n",
       "       [ 8., 11., 10., 10.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dados com valores ausentes \n",
    "dados = np.array([[1,2,3,np.nan],\n",
    "                [4,np.nan,6,7],\n",
    "                [8,2,5,7],\n",
    "                [8,11,10,10]\n",
    "                ])\n",
    "\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  8.],\n",
       "       [ 4.,  5.,  6.,  7.],\n",
       "       [ 8.,  2.,  5.,  7.],\n",
       "       [ 8., 11., 10., 10.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cria imputador com estrat√©gia de substituir pela m√©dia - por coluna/feature\n",
    "imputador1 = SimpleImputer(strategy='mean')\n",
    "\n",
    "dados_imputados1 = imputador1.fit_transform(dados)\n",
    "\n",
    "#Note que os valores vazios foram substituidos pela m√©dia\n",
    "dados_imputados1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  7.],\n",
       "       [ 4.,  2.,  6.,  7.],\n",
       "       [ 8.,  2.,  5.,  7.],\n",
       "       [ 8., 11., 10., 10.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cria imputador com estrat√©gia de substituir pelo valor mais frequente - por coluna/feature\n",
    "imputador2 = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "dados_imputados2 = imputador2.fit_transform(dados)\n",
    "\n",
    "#Note que os valores vazios foram substituidos pela m√©dia\n",
    "dados_imputados2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Identifica√ß√£o de Outliers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dist√¢ncia interquart√≠lica (IQR ‚Äì Interquartile Range) √© uma m√©trica estat√≠stica amplamente utilizada para detec√ß√£o de outliers em conjuntos de dados. Ela se baseia na distribui√ß√£o dos quartis, que dividem os dados em quatro partes iguais.\n",
    "\n",
    "Como funciona:\n",
    "\n",
    "1. Calcular os quartis:\n",
    "ùëÑ1 = 1¬∫ quartil (25% dos dados est√£o abaixo deste valor)\n",
    "Q3 = 3¬∫ quartil (75% dos dados est√£o abaixo deste valor)\n",
    "\n",
    "2. Calcular a dist√¢ncia interquart√≠lica (IQR):\n",
    "IQR=ùëÑ3‚àíùëÑ1\n",
    "\n",
    "3. Definir limites para detec√ß√£o de outliers:\n",
    "Os outliers s√£o valores que ficam fora do intervalo:\n",
    "Limite Inferior=ùëÑ1‚àí1.5√óIQR\n",
    "Limite Superior = ùëÑ3+1.5√óIQR \n",
    "\n",
    "Qualquer ponto fora desses limites √© considerado um outlier.\n",
    "\n",
    "Vantagens do IQR:\n",
    "- Baseado em quartis, menos sens√≠vel a valores extremos do que m√©dia e desvio padr√£o.\n",
    "- Simples de calcular e interpretar.\n",
    "- Funciona bem para distribui√ß√µes assim√©tricas.\n",
    "\n",
    "Limita√ß√µes:\n",
    "- Assumindo o fator 1.5, pode n√£o detectar outliers em distribui√ß√µes muito assim√©tricas ou com caudas pesadas.\n",
    "- N√£o fornece informa√ß√£o sobre a gravidade do outlier, apenas indica que ele √© extremo em rela√ß√£o √† distribui√ß√£o central."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contexto estat√≠stico:\n",
    "\n",
    "O fator 1.5 usado na regra da dist√¢ncia interquart√≠lica (IQR) tem um fundamento estat√≠stico relacionado √† distribui√ß√£o normal. Em uma distribui√ß√£o aproximadamente normal, cerca de 50% dos dados est√£o dentro do intervalo definido pelos quartis (Q1 a Q3). Multiplicar o IQR por 1.5 estende esse intervalo para cobrir a maior parte dos dados t√≠picos, mas ainda marca como outliers os valores muito afastados da mediana, que s√£o raros nessa distribui√ß√£o.\n",
    "\n",
    "Na pr√°tica, isso significa que, para dados que seguem uma distribui√ß√£o normal, o fator 1.5 identifica como outliers valores que est√£o aproximadamente al√©m de 2 desvios padr√£o do centro dos 50% centrais. Esse valor foi escolhido porque representa um bom equil√≠brio: ele √© suficientemente sens√≠vel para detectar pontos extremos, mas n√£o t√£o r√≠gido a ponto de classificar como outliers varia√ß√µes naturais do conjunto de dados.\n",
    "\n",
    "Essa regra se tornou um padr√£o porque funciona bem em muitas situa√ß√µes, mesmo quando os dados n√£o s√£o perfeitamente normais, e √© a base do boxplot, onde os ‚Äúbigodes‚Äù estendem-se at√© 1.5√óIQR e os pontos fora dele s√£o considerados outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5, 100])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados = np.array([1,2,3,4,5,100])\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Com q1 = 2.25 e q3 = 4.75, IQR = 2.5\n",
      "Os limites inferiores e superiores foram, respectivamente, de -1.5 e 8.5\n"
     ]
    }
   ],
   "source": [
    "q1 = np.percentile(dados, 25)\n",
    "q3 = np.percentile(dados, 75)\n",
    "iqr = q3 - q1 \n",
    "\n",
    "print(f'Com q1 = {q1} e q3 = {q3}, IQR = {iqr}')\n",
    "\n",
    "limite_inf = q1 - 1.5 * iqr\n",
    "limite_sup = q3 + 1.5 * iqr\n",
    "\n",
    "print(f'Os limites inferiores e superiores foram, respectivamente, de {limite_inf} e {limite_sup}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers = np.where((dados < limite_inf) | (dados > limite_sup))[0]\n",
    "outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#posicao do elemento em dados\n",
    "outliers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Valor do elemento em dados\n",
    "dados[outliers[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remo√ß√£o do outlier\n",
    "np.delete(dados, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Normaliza√ß√£o dos dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A normaliza√ß√£o de dados √© uma etapa fundamental, especialmente quando os atributos possuem escalas diferentes. O objetivo da normaliza√ß√£o √© transformar os dados para uma mesma escala, sem distorcer suas distribui√ß√µes, permitindo que algoritmos que dependem de dist√¢ncia ou gradiente ‚Äî como KNN, SVM, redes neurais e regress√£o log√≠stica ‚Äî funcionem corretamente.\n",
    "\n",
    "Por que normalizar os dados?\n",
    "- Muitos algoritmos assumem que todas as vari√°veis t√™m igual import√¢ncia. Se uma vari√°vel varia de 0 a 1.000 e outra de 0 a 1, a primeira dominar√° o aprendizado se os dados n√£o forem normalizados.\n",
    "- Facilita a converg√™ncia de algoritmos de otimiza√ß√£o, como o gradiente descendente.\n",
    "- Ajuda na interpreta√ß√£o e compara√ß√£o de diferentes atributos.\n",
    "\n",
    "Principais t√©cnicas de normaliza√ß√£o:\n",
    "\n",
    "**Min-Max Scaling**: \n",
    "- Transforma os valores para um intervalo fixo, normalmente entre 0 e 1, usando o valor m√≠nimo e m√°ximo de cada atributo.\n",
    "- Valores extremos s√£o ajustados ao limite do intervalo.\n",
    "- Muito usada quando os dados t√™m limites conhecidos.\n",
    "\n",
    "\n",
    "**Z-score (Padroniza√ß√£o ou Standardization)**\n",
    "- Centraliza os dados em torno da m√©dia e ajusta pela vari√¢ncia, de forma que os atributos tenham m√©dia zero e desvio padr√£o 1.\n",
    "- Ideal para dados com distribui√ß√µes aproximadamente normais.\n",
    "- Reduz impacto de escalas diferentes sem necessariamente limitar os valores a um intervalo fixo.\n",
    "\n",
    "    \n",
    "**Robust Scaling**\n",
    "- Usa mediana e IQR em vez de m√©dia e desvio padr√£o, tornando a transforma√ß√£o menos sens√≠vel a outliers.\n",
    "\n",
    "!! Observa√ß√µes importantes:\n",
    "- Nem todos os algoritmos precisam de normaliza√ß√£o: √°rvores de decis√£o e random forests, por exemplo, n√£o s√£o afetadas por escalas diferentes.\n",
    "- A escolha da t√©cnica depende do tipo de dados e do algoritmo que ser√° usado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 5, 6, 7, 8, 7, 6, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados = np.array([2,3,5,6,7,8,7,6,0])\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25 , 0.375, 0.625, 0.75 , 0.875, 1.   , 0.875, 0.75 , 0.   ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_normalizados = normalize([dados], norm = 'max')\n",
    "dados_normalizados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Normaliza√ß√£o L1 --> Tamb√©m chamada de norma Manhattan ou norma da soma absoluta. Cada valor do vetor √© dividido pela soma dos valores absolutos de todos os elementos do vetor.\n",
    "2. Normaliza√ß√£o L2 --> Tamb√©m chamada de norma Euclidiana. Cada valor do vetor √© dividido pela raiz quadrada da soma dos quadrados de todos os elementos do vetor.\n",
    "3. Normaliza√ß√£o max --> Cada valor do vetor √© dividido pelo maior valor absoluto do vetor. Resultado: o maior valor do vetor normalizado √© 1 (ou -1, se negativo)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tipo    | O que faz                                   | Resultado         |\n",
    "| ------- | ------------------------------------------- | ----------------- |\n",
    "| **L1**  | Divide pelo somat√≥rio dos valores absolutos | Soma absoluta = 1 |\n",
    "| **L2**  | Divide pela raiz da soma dos quadrados      | Magnitude = 1     |\n",
    "| **Max** | Divide pelo valor m√°ximo do vetor           | Maior valor = 1   |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Padroniza√ß√£o dos dados\n",
    "\n",
    "A padroniza√ß√£o de dados √© uma t√©cnica de pr√©-processamento usada para transformar os atributos de um conjunto de dados de forma que eles tenham m√©dia zero e desvio padr√£o igual a um. Cada valor do atributo √© transformado subtraindo-se a m√©dia e dividindo-se pelo desvio padr√£o do atributo.\n",
    "\n",
    "Por que padronizar os dados?\n",
    "- Muitos algoritmos de aprendizado de m√°quina, como regress√£o linear, SVM, K-means e redes neurais, funcionam melhor quando os atributos t√™m mesma escala e distribui√ß√£o centralizada.\n",
    "- Evita que vari√°veis com valores grandes dominem o aprendizado em rela√ß√£o a vari√°veis com valores menores.\n",
    "- Facilita a converg√™ncia de algoritmos que usam gradiente descendente, tornando o treinamento mais est√°vel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "padronizador = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.22474487, -1.22474487, -1.22474487],\n",
       "       [ 0.        ,  0.        ,  0.        ],\n",
       "       [ 1.22474487,  1.22474487,  1.22474487]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_padronizados = padronizador.fit_transform(dados)\n",
    "dados_padronizados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Codifica√ß√£o de vari√°veis categ√≥ricas\n",
    "\n",
    "A codifica√ß√£o de vari√°veis categ√≥ricas √© uma t√©cnica de pr√©-processamento de dados usada em aprendizado de m√°quina para transformar vari√°veis n√£o num√©ricas (categ√≥ricas) em valores num√©ricos, que os algoritmos conseguem interpretar.\n",
    "\n",
    "Por que codificar?\n",
    "- A maioria dos algoritmos de machine learning n√£o consegue trabalhar diretamente com textos ou categorias (como ‚Äúvermelho‚Äù, ‚Äúazul‚Äù, ‚Äúverde‚Äù).\n",
    "- A codifica√ß√£o permite que essas informa√ß√µes sejam representadas numericamente, sem perder o significado das categorias."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1 One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'A', 'B'], dtype='<U1')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_categoricos = np.array(['A', 'B', 'C', 'A', 'B'])\n",
    "dados_categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "codific_one_hot = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "dados_one_hot = codific_one_hot.fit_transform(dados_categoricos.reshape(-1,1))\n",
    "print(dados_one_hot.toarray())\n",
    "\n",
    "#Note que A, B e C viraram colunas e 1 representa que aquela variavel se aplica e 0 que n√£o se aplica"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.2 Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "codific_label = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 0 1]\n"
     ]
    }
   ],
   "source": [
    "dados_label = codific_label.fit_transform(dados_categoricos.reshape(-1,1))\n",
    "print(dados_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a20864f8b4a82cb8684ab72d0af1911f5189068ff821a3497877c5916d396164"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
